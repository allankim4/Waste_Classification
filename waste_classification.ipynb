{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----------WARNING-----------WARNING-----------WARNING-----------WARNING-----------WARNING-----------WARNING\n",
    "#Running the whole notebook without a GPU, CUDA, CUDNN, and Tensorflow-GPU may take 8+ hours of compiling per model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/test, and reshape them\n",
    "data_test = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        'Images/Split/test', \n",
    "        target_size=(224, 224), \n",
    "        batch_size = 850, \n",
    "        seed = 1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20060 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        'Images/Split/train', \n",
    "        target_size=(224, 224), \n",
    "        batch_size = 8500, \n",
    "        seed = 1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images and labels\n",
    "images_train, labels_train = next(data_train)\n",
    "images_test, labels_test= next(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all images and labels\n",
    "images = np.concatenate((images_train, images_test))\n",
    "labels = np.concatenate((labels_train[:,0], labels_test[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Random Split for test data\n",
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size=0.20, random_state=1234)\n",
    "\n",
    "#Creating Random Split for validation and training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Convolutional Neural Network\n",
    "cnn = models.Sequential()\n",
    "\n",
    "#1st Layer\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224,  3), padding='SAME'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#2nd Layer\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Configuring CNN\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adagrad\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5984 samples, validate on 1496 samples\n",
      "Epoch 1/100\n",
      "5984/5984 [==============================] - 9s 1ms/step - loss: 1.1124 - accuracy: 0.7005 - val_loss: 0.4320 - val_accuracy: 0.8122\n",
      "Epoch 2/100\n",
      "5984/5984 [==============================] - 9s 1ms/step - loss: 0.4315 - accuracy: 0.8155 - val_loss: 0.4263 - val_accuracy: 0.8102\n",
      "Epoch 3/100\n",
      "5984/5984 [==============================] - 9s 1ms/step - loss: 0.3893 - accuracy: 0.8397 - val_loss: 0.4063 - val_accuracy: 0.8302\n",
      "Epoch 4/100\n",
      "5984/5984 [==============================] - 9s 1ms/step - loss: 0.3318 - accuracy: 0.8635 - val_loss: 0.4369 - val_accuracy: 0.8215\n",
      "Epoch 5/100\n",
      "5664/5984 [===========================>..] - ETA: 0s - loss: 0.2753 - accuracy: 0.8907"
     ]
    }
   ],
   "source": [
    "#Training CNN\n",
    "cnn1 = cnn.fit(X_train,\n",
    "               y_train,\n",
    "               epochs=100,\n",
    "               batch_size=32,\n",
    "               validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Summary\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_cnn = cnn1.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss - 2-Layer CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy - 2-Layer CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.savefig('Images/Model/cnn1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Metrics\n",
    "results_train = cnn.evaluate(X_train, y_train)\n",
    "results_test = cnn.evaluate(X_test, y_test)\n",
    "print()\n",
    "print('CNN [Loss, Accuracy]')\n",
    "print('CNN TRAIN IMAGES: ', results_train)\n",
    "print()\n",
    "print('CNN TEST IMAGES: ', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Layer CNN with Transfer Learning (InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing model with weights pre-trained on ImageNet\n",
    "from keras.applications import inception_v3\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizing InceptionV3 for new CNN\n",
    "imagenet=inception_v3.InceptionV3(weights='imagenet',include_top=False)\n",
    "imagenet_new=imagenet.output\n",
    "cnn2 = models.Sequential()\n",
    "cnn2.add(imagenet)\n",
    "cnn2.add(GlobalAveragePooling2D())\n",
    "cnn2.add(Dense(1024,activation='relu'))\n",
    "cnn2.add(Dense(1024,activation='relu')) #dense layer 2\n",
    "cnn2.add(Dense(512,activation='relu')) #dense layer 3\n",
    "cnn2.add(Dense(1,activation='sigmoid')) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring exracted model is not retrained\n",
    "for layer in cnn2.layers[:1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "tl_cnn2 = cnn2.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=50,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_transfer = cnn2.predict(X_test)\n",
    "predictions_transfer = np.around(predictions_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predictions_transfer), classes=['Organic', 'Recyclable'], normalize=False,\n",
    "                      title='Confusion matrix - ImagenetV3')\n",
    "# plt.savefig('Images/Model/CF_TL1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_cnn = tl_cnn2.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss - Inception V3')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy - Inception V3')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.savefig('Images/Model/cnn2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictoneimage_cnn(model, path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    plt.imshow(img)\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    predict = model.predict(img)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictoneimage_cnn(cnn2, 'Images/Sample_Images/styro.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictoneimage_cnn(cnn, 'Images/Sample_Images/styro.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Models\n",
    "# cnn.save('image_class1.h5')\n",
    "# cnn2.save('image_class1_tl.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = models.Sequential()\n",
    "\n",
    "#1st Layer\n",
    "cnn3.add(layers.Conv2D(128, (3, 3), input_shape=(224, 224,  3), padding='SAME'))\n",
    "cnn3.add(layers.Activation('relu'))\n",
    "cnn3.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#2nd Layer\n",
    "cnn3.add(layers.Conv2D(64, (3, 3)))\n",
    "cnn3.add(layers.Activation('relu'))\n",
    "cnn3.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#3rd Layer\n",
    "cnn3.add(layers.Conv2D(32, (3, 3)))\n",
    "cnn3.add(layers.Activation('relu'))\n",
    "cnn3.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Dense and output Layers\n",
    "cnn3.add(layers.Flatten())\n",
    "cnn3.add(layers.Dense(32))\n",
    "cnn3.add(layers.Activation('relu'))\n",
    "cnn3.add(layers.Dropout(0.5))\n",
    "cnn3.add(layers.Dense(1))\n",
    "cnn3.add(layers.Activation('sigmoid'))\n",
    "\n",
    "#Configuring the model\n",
    "cnn3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_3l = cnn3.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=50,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_cnn = cnn_3l.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss - 3-Layer CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy - 3-Layer CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.savefig('Images/Model/cnn3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn3.save('image_class2_3l.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Layer CNN with Transfer Learning (Xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing pre-trained model\n",
    "from keras.applications import xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pre-trained CNN Model\n",
    "imagenet2 = xception.Xception(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "imagenet2_res = imagenet2.output\n",
    "cnn3_tl = models.Sequential()\n",
    "cnn3_tl.add(imagenet2)\n",
    "cnn3_tl.add(GlobalAveragePooling2D())\n",
    "cnn3_tl.add(Dense(1024,activation='relu'))\n",
    "cnn3_tl.add(Dense(1024,activation='relu')) \n",
    "cnn3_tl.add(Dense(512,activation='relu')) \n",
    "cnn3_tl.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring exracted model is not retrained\n",
    "for layer in cnn3_tl.layers[:1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3_tl.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "tl_cnn3 = cnn3_tl.fit(X_train,\n",
    "                      y_train,\n",
    "                      epochs=10,\n",
    "                      batch_size=50,\n",
    "                      validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn3_tl.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_cnn = tl_cnn3.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss - Xception Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy - Xception Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.savefig('Images/Model/cnn3_tl.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it can classify a confusing image of styrofoam ball\n",
    "predictoneimage_cnn(cnn3_tl, 'Images/Sample_Images/styro.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Robot\n",
    "predictoneimage_cnn(cnn3_tl, 'Images/Sample_Images/robot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn3_tl.save('image_class2_3l_tl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_predictor(path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    plt.imshow(img)\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)    \n",
    "    pred1 = cnn.predict(img)\n",
    "    pred2 = cnn3.predict(img)\n",
    "    pred3 = cnn2.predict(img)\n",
    "    pred4 = cnn3_tl.predict(img)\n",
    "    return pred1, pred2, pred3, pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_output(path):\n",
    "    mod1, mod2, mod3, mod4 = image_predictor(path)\n",
    "    print('VALUE Interpretation:')\n",
    "    print()\n",
    "    print('Closer to 1 is Organic, Closer to 0 is Recyclable')\n",
    "    print()\n",
    "    print('2-LAYER CNN:')\n",
    "    print(mod1)\n",
    "    print()\n",
    "    print('3-Layer CNN:')\n",
    "    print(mod2)\n",
    "    print()\n",
    "    print('Inception ver3 CNN')\n",
    "    print(mod3)\n",
    "    print()\n",
    "    print('Xception CNN')\n",
    "    print(mod4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Prediction\n",
    "predictor_output('Images/Sample_Images/robot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
